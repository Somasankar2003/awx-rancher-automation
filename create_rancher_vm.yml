---
- name: Create multiple VMs on OpenStack and auto-register to Rancher
  hosts: localhost
  connection: local
  gather_facts: no

  vars:
    # Rancher details
    rancher_url: "https://192.168.210.32"
    rancher_token: "token-kt4rg:zppllkvsr7xl5cndlb4n4njqbckzjsmkd557xbgmh69bzdc7kqrkbl"
    cluster_name: "{{ cluster_name }}"

    # Survey variables
    vm_count: "{{ vm_count | int }}"
    node_roles: "{{ node_roles }}"
    vm_net: "{{ vm_net }}"
    vm_flavor: "{{ vm_flavor }}"
    vm_names_list: "{{ vm_name_prefix.split(',') }}"

    # VM details
    vm_image: "494c4e8c-d11b-43b7-9e8b-df4009b7102b"
    vm_keypair: "k8s"

    # OpenStack auth
    os_auth_url: "http://192.168.170.50:5000"
    os_project_name: "Production Engineering"
    os_project_domain_id: "default"
    os_username: "admin"
    os_user_domain_name: "Default"
    os_password: "bLEZFvatBShkvUZyKrasUjmNdTTc9c3HcxWykrro"
    os_region_name: "RegionOne"
    os_interface: "public"
    os_identity_api_version: "3"

  tasks:
    ###########################################################################
    # SMART ROLE HANDLING
    ###########################################################################
    - name: Determine role assignment mode
      set_fact:
        # Single VM with multiple roles
        single_vm_multiple_roles: "{{ vm_count == 1 and ',' in node_roles }}"
        # Multiple VMs with single roles each
        multi_vm_single_roles: "{{ vm_count > 1 and node_roles.split(',') | length == vm_count }}"
        # Multiple VMs with multiple roles (uncommon but handled)
        multi_vm_multi_roles: "{{ vm_count > 1 and node_roles.split(',') | length != vm_count }}"

    - name: Validate configuration
      block:
        - name: Check basic requirements
          assert:
            that:
              - vm_count >= 1
              - vm_names_list | length == vm_count
            fail_msg: |
              Validation failed:
              - vm_count must be >= 1 (got {{ vm_count }})
              - VM names count ({{ vm_names_list | length }}) must match vm_count ({{ vm_count }})
        
        - name: Check role configuration
          assert:
            that:
              - single_vm_multiple_roles or multi_vm_single_roles or multi_vm_multi_roles
            fail_msg: |
              Role configuration error:
              For 1 VM: Use comma-separated roles (e.g., "etcd,controlplane,worker")
              For multiple VMs: Use comma-separated roles matching VM count (e.g., "etcd,controlplane,worker" for 3 VMs)
              Current: vm_count={{ vm_count }}, roles={{ node_roles }}

    - name: Build VM role mapping based on mode
      block:
        - name: Single VM with multiple roles
          set_fact:
            vm_role_map: "{{ [ (vm_names_list[0], node_roles) ] }}"
          when: single_vm_multiple_roles
        
        - name: Multiple VMs with single roles
          set_fact:
            parsed_roles: "{{ node_roles.split(',') }}"
            vm_role_map: "{{ vm_names_list | zip(parsed_roles) | list }}"
          when: multi_vm_single_roles
        
        - name: Multiple VMs with multiple roles (all get same roles)
          set_fact:
            vm_role_map: "{{ vm_names_list | map('regex_replace', '$', ' ' + node_roles) | list | map('split') | map('list') }}"
          when: multi_vm_multi_roles

    - name: Display VM-Role mapping
      debug:
        msg: "VM '{{ item.0 }}' ‚Üí Roles: {{ item.1 }}"
      loop: "{{ vm_role_map }}"

    ###########################################################################
    # GET RANCHER CLUSTER INFO
    ###########################################################################
    - name: Get cluster ID from Rancher
      uri:
        url: "{{ rancher_url }}/v3/clusters?name={{ cluster_name }}"
        method: GET
        headers:
          Authorization: "Bearer {{ rancher_token }}"
        validate_certs: no
      register: cluster_info

    - name: Fail if cluster not found
      fail:
        msg: "Cluster '{{ cluster_name }}' not found in Rancher. Create it in Rancher UI first."
      when: cluster_info.json.data | length == 0

    - set_fact:
        cluster_id: "{{ cluster_info.json.data[0].id }}"

    - debug:
        msg: "Found cluster '{{ cluster_name }}' with ID: {{ cluster_id }}"

    ###########################################################################
    # GET RANCHER JOIN TOKEN
    ###########################################################################
    - name: Check for existing registration tokens
      uri:
        url: "{{ rancher_url }}/v3/clusterRegistrationTokens?clusterId={{ cluster_id }}"
        method: GET
        headers:
          Authorization: "Bearer {{ rancher_token }}"
        validate_certs: no
      register: existing_tokens

    - name: Create registration token if needed
      uri:
        url: "{{ rancher_url }}/v3/clusterRegistrationTokens"
        method: POST
        headers:
          Authorization: "Bearer {{ rancher_token }}"
        validate_certs: no
        body_format: json
        body:
          clusterId: "{{ cluster_id }}"
      when: existing_tokens.json.data | length == 0
      ignore_errors: yes

    - name: Wait for node command to be ready
      uri:
        url: "{{ rancher_url }}/v3/clusterRegistrationTokens?clusterId={{ cluster_id }}"
        method: GET
        headers:
          Authorization: "Bearer {{ rancher_token }}"
        validate_certs: no
      register: reg_info
      until: 
        - reg_info.json.data[0].nodeCommand is defined
        - reg_info.json.data[0].nodeCommand != ""
      retries: 15
      delay: 3

    - set_fact:
        node_command_raw: "{{ reg_info.json.data[0].nodeCommand }}"
        rancher_token_id: "{{ reg_info.json.data[0].token }}"

    # Fix for self-signed certificates
    - set_fact:
        node_command: "{{ node_command_raw | replace('curl ', 'curl -k ') }}"

    - debug:
        msg: "Join command ready (token: {{ rancher_token_id[:15] }}...)"

    ###########################################################################
    # CREATE VMS WITH FIXED CLOUD-INIT
    ###########################################################################
    - name: Create cloud-init files
      copy:
        dest: "/tmp/cloud-init-{{ item.0 }}.yml"
        content: |
          #cloud-config
          package_update: true
          packages:
            - curl
            - docker.io
            - jq
            - nfs-common

          write_files:
            - path: /etc/hostname
              content: "{{ item.0 }}\n"
              owner: root:root
              permissions: '0644'
            
            - path: /etc/docker/daemon.json
              content: |
                {
                  "exec-opts": ["native.cgroupdriver=systemd"],
                  "log-driver": "json-file",
                  "storage-driver": "overlay2"
                }
              owner: root:root
              permissions: '0644'

          runcmd:
            # Set hostname
            - hostnamectl set-hostname {{ item.0 }}
            
            # Configure Docker
            - systemctl enable docker
            - systemctl start docker
            - systemctl restart docker
            
            # Disable swap (required for Kubernetes)
            - swapoff -a
            - sed -i '/swap/d' /etc/fstab
            
            # Wait for network
            - sleep 10
            
            # Build final join command
            - |
              FINAL_CMD='{{ node_command }}'
              
              # Add role flags based on item.1 (which could be single or comma-separated roles)
              {% if 'etcd' in item.1 %}FINAL_CMD="$FINAL_CMD --etcd"{% endif %}
              {% if 'controlplane' in item.1 %}FINAL_CMD="$FINAL_CMD --controlplane"{% endif %}
              {% if 'worker' in item.1 %}FINAL_CMD="$FINAL_CMD --worker"{% endif %}
              
              # Add node name (CRITICAL for OpenStack)
              FINAL_CMD="$FINAL_CMD --node-name {{ item.0 }}"
              
              echo "Executing: $FINAL_CMD"
              echo "$FINAL_CMD" > /root/join.sh
              chmod +x /root/join.sh
            
            # Execute with retries
            - |
              for i in {1..5}; do
                echo "Join attempt $i"
                if /root/join.sh 2>&1 | tee /root/join_attempt_$i.log; then
                  echo "‚úÖ Joined successfully"
                  break
                else
                  echo "‚ùå Attempt $i failed, retrying in 15s..."
                  sleep 15
                fi
              done
            
            # Verify
            - sleep 5
            - docker ps | grep rancher || echo "No rancher containers yet"
      loop: "{{ vm_role_map }}"

    ###########################################################################
    # CREATE VMS ON OPENSTACK
    ###########################################################################
    - name: Create VM on OpenStack
      openstack.cloud.server:
        state: present
        name: "{{ item.0 }}"
        image: "{{ vm_image }}"
        flavor: "{{ vm_flavor }}"
        key_name: "{{ vm_keypair }}"
        network: "{{ vm_net }}"
        userdata: "{{ lookup('file', '/tmp/cloud-init-' + item.0 + '.yml') }}"
        auto_ip: yes
        wait: yes
        timeout: 300
        config_drive: yes
        security_groups: "default"
      environment:
        OS_AUTH_URL: "{{ os_auth_url }}"
        OS_PROJECT_NAME: "{{ os_project_name }}"
        OS_PROJECT_DOMAIN_ID: "{{ os_project_domain_id }}"
        OS_USERNAME: "{{ os_username }}"
        OS_USER_DOMAIN_NAME: "{{ os_user_domain_name }}"
        OS_PASSWORD: "{{ os_password }}"
        OS_REGION_NAME: "{{ os_region_name }}"
        OS_INTERFACE: "{{ os_interface }}"
        OS_IDENTITY_API_VERSION: "{{ os_identity_api_version }}"
      loop: "{{ vm_role_map }}"
      register: vms

    - name: Show VM IPs
      debug:
        msg: "VM {{ item.0 }} created - IP: {{ vms.results[loop.index0].server.accessIPv4 }}"
      loop: "{{ vm_names_list }}"

    ###########################################################################
    # WAIT FOR NODES TO REGISTER
    ###########################################################################
    - name: Wait for nodes to appear in Rancher API
      uri:
        url: "{{ rancher_url }}/v3/nodes?clusterId={{ cluster_id }}"
        method: GET
        headers:
          Authorization: "Bearer {{ rancher_token }}"
        validate_certs: no
      register: rancher_nodes
      until: rancher_nodes.json.data | length >= vm_count
      retries: 30
      delay: 10

    - name: Check node registration
      debug:
        msg: |
          ‚úÖ Nodes registered: {{ rancher_nodes.json.data | length }}/{{ vm_count }}
          {% for node in rancher_nodes.json.data %}
          - {{ node.name }} ({{ node.state }}) - {{ node.roles | join(',') }}
          {% endfor %}

    ###########################################################################
    # WAIT FOR CLUSTER TO BECOME ACTIVE
    ###########################################################################
    - name: Monitor cluster activation
      uri:
        url: "{{ rancher_url }}/v3/clusters/{{ cluster_id }}"
        method: GET
        headers:
          Authorization: "Bearer {{ rancher_token }}"
        validate_certs: no
      register: cluster_status
      until: >
        cluster_status.json.state == "active" and
        cluster_status.json.conditions is defined and
        (cluster_status.json.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first | default('False')) == "True"
      retries: 50
      delay: 10

    - name: Final cluster status
      debug:
        msg: |
          {{ 'üéâ CLUSTER ACTIVE!' if cluster_status.json.state == 'active' else '‚ö†Ô∏è  Cluster not active' }}
          
          Cluster: {{ cluster_name }}
          State: {{ cluster_status.json.state }}
          ID: {{ cluster_id }}
          
          Conditions:
          {% for condition in cluster_status.json.conditions %}
          - {{ condition.type }}: {{ condition.status }}
          {% endfor %}
          
          Access at: {{ rancher_url }}/c/{{ cluster_id }}

    ###########################################################################
    # CLEANUP
    ###########################################################################
    - name: Clean temp files
      file:
        path: "/tmp/cloud-init-{{ item }}.yml"
        state: absent
      loop: "{{ vm_names_list }}"

    - name: Success message
      debug:
        msg: |
          ‚úÖ SUCCESS!
          Cluster: {{ cluster_name }}
          State: {{ cluster_status.json.state }}
          VMs: {{ vm_names_list | join(', ') }}
